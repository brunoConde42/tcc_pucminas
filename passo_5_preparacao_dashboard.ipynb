{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação da base para leitura do Dashboard\n",
    "Algumas transformações precisam ser realizadas para exibição no dashbard.\n",
    "1. Limpeza e carga das colunas NEGATIVO, POSTIVO, NEUTRO e SPAM\n",
    "2. Tratamento para nuvem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import unidecode\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando \n",
    "df = pd.read_pickle('dados_twitter_ans_classificados_analisados.pkl')\n",
    "\n",
    "#limpar colunas\n",
    "df['POSITIVO'] = 0\n",
    "df['NEGATIVO'] = 0\n",
    "df['NEUTRO'] = 0\n",
    "df['SPAM'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando \n",
    "df['POLARIDADE'] = ''\n",
    "for index,row in df.iterrows():\n",
    "    if row['valor_sentimento'] == 0:\n",
    "        df.at[index,'NEUTRO'] = 1\n",
    "        df.at[index,'POLARIDADE'] = 'NEUTRO'\n",
    "    elif row['valor_sentimento'] > 0:\n",
    "        df.at[index,'POSITIVO'] = 1\n",
    "        df.at[index,'POLARIDADE'] = 'POSTIVO'\n",
    "    elif row['valor_sentimento'] < 0:\n",
    "        df.at[index,'NEGATIVO'] = 1\n",
    "        df.at[index,'POLARIDADE'] = 'NEGATIVO'\n",
    "        \n",
    "#definindo a coluna index como str\n",
    "df['id']=df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a nuvem de palavras\n",
    "Será passado para minusculas e removido URL, usuários, HASHTAGS, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    \n",
    "    return \" \".join(re.sub(r'http\\S+', '', txt, flags=re.MULTILINE).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_users(txt):\n",
    "    \n",
    "    return \" \".join(re.sub(r'@\\S+',\"\",txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, *stopwords):\n",
    "\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lups/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#aplicando minusculas\n",
    "df[\"nuvem_palavras\"] = df.text.apply(str.lower)\n",
    "\n",
    "#adiconando a coluna text_tratada removendo as urls\n",
    "df[\"nuvem_palavras\"] = df.nuvem_palavras.apply(remove_url)\n",
    "df[\"nuvem_palavras\"] = df.nuvem_palavras.apply(remove_users)\n",
    "\n",
    "df[\"nuvem_palavras\"] = df['nuvem_palavras'].str.replace('[^\\w\\s]','')\n",
    "df[\"nuvem_palavras\"] = df['nuvem_palavras'].apply(unidecode.unidecode)\n",
    "\n",
    "#baixando as stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words_acento = set(stopwords.words('portuguese'))\n",
    "#retirando acentuacao\n",
    "stop_words = set([unidecode.unidecode(word) for word in stop_words_acento])\n",
    "#adicionando palavras que nao vieram nas stopwords\n",
    "tirar_essas_tambem = set([\n",
    "'e','a','pra','o','nao','dia','ta','dm','vc','ser','vcs','que','ai',\n",
    "'q','vai','tar','ola','faz','fazer','ter','p','pq','to','ne'])\n",
    "#retirando palavras\n",
    "df[\"nuvem_palavras\"] = df.nuvem_palavras.apply(remove_stopwords,args=stop_words)\n",
    "df[\"nuvem_palavras\"] = df.nuvem_palavras.apply(remove_stopwords,args=tirar_essas_tambem)\n",
    "\n",
    "#colocando todas as palavras em uma única lista\n",
    "palavras_tweets = [tweet.lower().split() for tweet in df['nuvem_palavras']]\n",
    "todas_palavras = list(itertools.chain(*palavras_tweets))\n",
    "\n",
    "#contando as palavras\n",
    "frequencia_palavras = collections.Counter(todas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando os usuários\n",
    "Será criado um campo a mais para classificar o número quanto ao numero de usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando novas colunas\n",
    "df['USER_SEGUIDORES'] = ''\n",
    "df['USER_SEGUIDORES_SEGUIDORES'] = ''\n",
    "df['USER_SEGUIDORES_ALTA'] = 0\n",
    "df['USER_SEGUIDORES_MEDIA'] = 0\n",
    "df['USER_SEGUIDORES_BAIXA'] = 0\n",
    "df['USER_SEGUIDORES_ALTO'] = 0\n",
    "df['USER_SEGUIDORES_MEDIO'] = 0\n",
    "df['USER_SEGUIDORES_BAIXO'] = 0\n",
    "df['USER_SEGUIDORES_SINISTRO'] = 0\n",
    "df['USER_SEGUIDORES_SINISTRA'] = 0\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row['followers_count'] in range(0,100):\n",
    "        df.at[index,'USER_SEGUIDORES'] = 'BAIXA'\n",
    "        df.at[index,'USER_SEGUIDORES_BAIXO'] = 1\n",
    "    elif row['followers_count'] in range(101,1000):\n",
    "        df.at[index,'USER_SEGUIDORES'] = 'MEDIA'\n",
    "        df.at[index,'USER_SEGUIDORES_MEDIO'] = 1\n",
    "    elif row['followers_count'] in range(1001,100000):\n",
    "        df.at[index,'USER_SEGUIDORES'] = 'ALTA'\n",
    "        df.at[index,'USER_SEGUIDORES_ALTO'] = 1\n",
    "    elif row['followers_count'] > 100000:\n",
    "        df.at[index,'USER_SEGUIDORES'] = 'SINISTRA'         \n",
    "        df.at[index,'USER_SEGUIDORES_SINISTRO'] = 1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = pd.ExcelWriter(\"tweets_ans.xlsx\", datetime_format='mmm d yyyy hh:mm:ss')\n",
    "df.to_excel(\"tweets_ans.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
